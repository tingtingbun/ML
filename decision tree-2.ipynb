{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as math\n",
    "import csv as csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(pred_list):\n",
    "        value,label_quantity = np.unique(pred_list, return_counts=True)\n",
    "        length = len(pred_list)\n",
    "        if length == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            prob  = label_quantity/length\n",
    "            en = 0 \n",
    "            for c in prob:\n",
    "                en += c*m.log2(c)\n",
    "            return (-en)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(curr_var, ds):\n",
    "        #calculating conditional entropy \n",
    "        predict_list = []\n",
    "        var_list = []\n",
    "        for i in range(len(ds)):\n",
    "            predict_list.append(ds[i][-1]) \n",
    "            var_list.append(ds[i][curr_var])\n",
    "        var_el = list(set(var_list))\n",
    "        final_list = list(zip(var_list,predict_list))\n",
    "        split1 = []\n",
    "        split2 = []\n",
    "        for tup in (final_list):\n",
    "            if tup[0]== var_el[0]:\n",
    "                split1.append(tup[-1])\n",
    "            elif tup [0]== var_el[1]:\n",
    "                split2.append(tup[-1])\n",
    "        total_len= len(split1)+len(split2)\n",
    "        cond_en = (len(split1)/total_len)*entropy(split1) + (len(split2)/total_len)*entropy(split2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_index_node (ds):\n",
    "        variables = ds[0][:-1]\n",
    "        mi = []\n",
    "        for v in range(len(variables)):\n",
    "            mi.append(mutual_information(v,ds))\n",
    "        index = mi.index(max(mi))\n",
    "        return {\"index\":index}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split (index, data_list):\n",
    "    #print(\"index:\",index)\n",
    "        select = []\n",
    "        for i in data_list:\n",
    "            select.append(i[index])\n",
    "        select=list(set(select))\n",
    "        list_1=[]\n",
    "        list_2=[]\n",
    "        for i in data_list:\n",
    "            if  i[index]==select[0]:\n",
    "                list_1.append(i)\n",
    "            elif i[index]==select[1]:\n",
    "                list_2.append(i)\n",
    "        a = len(list_1) + len(list_2)\n",
    "        return [select,[list_1,list_2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainStump (node, ds, max_depth, depth):\n",
    "    \n",
    "   \n",
    "        if len(ds) <=1:\n",
    "            node['predict']=classify(ds)\n",
    "            return\n",
    "    \n",
    "        splits = get_split(node[\"index\"],ds)\n",
    "        num_att = len(ds[0])-1\n",
    "    \n",
    "        \n",
    "    \n",
    "        if mutual_information(node[\"index\"],ds) <= 0.0 or mutual_information(node[\"index\"],ds) == -0.0 :\n",
    "            print(node)\n",
    "            node['predict'] = classify(splits[1][0]+splits[1][1])\n",
    "        \n",
    "        \n",
    "            return\n",
    "\n",
    "        if depth >= max_depth: \n",
    "            print(node)\n",
    "            node['predict']= classify(splits[1][0]+splits[1][1])\n",
    "        \n",
    "            return\n",
    "   \n",
    "        if depth >= num_att: \n",
    "            print(node)\n",
    "            node['predict']= classify(splits[1][0]+splits[1][1])\n",
    "        \n",
    "            return\n",
    "    \n",
    "        else:  \n",
    "        \n",
    "        \n",
    "            if len(splits[1][0])==0:\n",
    "                node[\"left\"]=classify(splits[1][0]+splits[1][1])\n",
    "                node[\"right\"]=get_best_index_node (splits[1][1])\n",
    "                node[\"left\"][\"val\"]=splits[0][0]\n",
    "                node[\"right\"][\"val\"]=splits[0][1]\n",
    "                TrainStump(node[\"right\"],splits[1][1],max_depth, depth+1)\n",
    "            \n",
    "            \n",
    "        \n",
    "            if len(splits[1][1])==0:\n",
    "           \n",
    "                node[\"right\"]=classify(splits[1][0]+splits[1][1])\n",
    "                node[\"left\"]=get_best_index_node (splits[1][1])\n",
    "            \n",
    "                node[\"left\"][\"val\"]=splits[0][0]\n",
    "                node[\"right\"][\"val\"]=splits[0][1]\n",
    "                TrainStump(node[\"left\"],splits[1][0],max_depth, depth+1)\n",
    "        \n",
    "            else:\n",
    "                node[\"left\"]=get_best_index_node (splits[1][0])\n",
    "                node[\"right\"]=get_best_index_node (splits[1][1])\n",
    "    \n",
    "                node[\"left\"][\"val\"]=splits[0][0]\n",
    "                node[\"right\"][\"val\"]=splits[0][1]\n",
    "                TrainStump(node[\"left\"],splits[1][0],max_depth, depth+1)\n",
    "                TrainStump(node[\"right\"],splits[1][1],max_depth, depth+1)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTree (train_data, max_depth):\n",
    "        root = get_best_index_node(train_data)\n",
    "        TrainStump(root,train_data,max_depth, depth=0)\n",
    "        return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, depth=0):\n",
    "        if isinstance(node, dict):\n",
    "            print(depth*' ',depth, 'f'+str(node['index']))\n",
    "            if \"left\" in node.keys():\n",
    "                print_tree(node['left'], depth+1)\n",
    "            if \"right\" in node.keys():\n",
    "                print_tree(node['right'], depth+1)\n",
    "        else:\n",
    "            print(depth*' ',depth, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify (split):\n",
    "        class_data=[]\n",
    "        for r in split:\n",
    "            class_data.append(r[-1])\n",
    "\n",
    "        return max(class_data, key=class_data.count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (test_data, tree):\n",
    "        if \"predict\" in tree.keys():\n",
    "            return (tree[\"predict\"])\n",
    "        \n",
    "    \n",
    "        else:\n",
    "            if test_data[tree[\"index\"]]==tree[\"left\"][\"val\"]:\n",
    "                return(predict(test_data, tree[\"left\"]))\n",
    "        \n",
    "            if test_data[tree[\"index\"]]==tree[\"right\"][\"val\"]:\n",
    "                return(predict(test_data, tree[\"right\"]))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate (dataset, tree):\n",
    "        correct=[]\n",
    "        wrong=[]\n",
    "        for row in dataset:\n",
    "            p=predict(row,tree)\n",
    "            if p == row[-1]:\n",
    "                correct.append(p)\n",
    "            else:\n",
    "                wrong.append(p)\n",
    "        error_rate = 1-(len(correct)/(len(correct)+len(wrong)))\n",
    "        return error_rate\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    with open (sys.argv[1],\"rt\") as input1:\n",
    "            list1 = []\n",
    "            for line in input1:\n",
    "                line = line[:-1].split(',')\n",
    "                list1.append(line)\n",
    "            list1.pop(0)\n",
    "            dataset1=list1\n",
    "            tree=CreateTree(dataset1,int(sys.argv[3]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with open (sys.argv[4],\"wt\") as output1:\n",
    "        for row in dataset1:\n",
    "            a=predict(row,tree)\n",
    "            output1.write(a +'\\n')\n",
    "            \n",
    "    \n",
    "    with open (sys.argv[2],\"rt\") as input2:\n",
    "        list2 = []\n",
    "        for line in input2:\n",
    "            line = line[:-1].split(',')\n",
    "            list2.append(line)\n",
    "        list2.pop(0)\n",
    "        dataset2=list2\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    with open (sys.argv[5],\"wt\") as output2:\n",
    "        for row in dataset2:\n",
    "            a=predict(row,tree)\n",
    "            output2.write(a +'\\n')\n",
    "        \n",
    "\n",
    "    with open (sys.argv[6],\"wt\") as output3:\n",
    "        err_rate_train = error_rate (dataset1,tree)\n",
    "        err_rate_test = error_rate (dataset2,tree)\n",
    "        output3.write(\"error(train): \" + str(err_rate_train)+\"\\n\")\n",
    "        output3.write(\"error(test): \" + str(err_rate_test))\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
